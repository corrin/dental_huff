{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T00:59:38.019453Z",
     "start_time": "2024-10-25T00:59:38.013266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ratings_to_size(rating):\n",
    "    return (math.sqrt(rating) + 20) / 10"
   ],
   "id": "4ef29f436530bdf5",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T00:59:39.227940Z",
     "start_time": "2024-10-25T00:59:38.038474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the database credentials from environment variables\n",
    "user = os.getenv(\"MYSQL_USER\")\n",
    "password = os.getenv(\"MYSQL_PASSWORD\")\n",
    "host = os.getenv(\"MYSQL_HOST\")\n",
    "database = os.getenv(\"MYSQL_DATABASE\")\n",
    "\n",
    "# Create an SQLAlchemy engine for the connection\n",
    "engine = create_engine(f\"mysql+pymysql://{user}:{password}@{host}/{database}\")\n",
    "\n",
    "# Query to retrieve latitude and longitude\n",
    "query = \"SELECT latitude, longitude FROM address WHERE location_type = 'ROOFTOP';\"\n",
    "\n",
    "# Load data into a pandas DataFrame\n",
    "raw_df = pd.read_sql(query, engine)\n",
    "\n",
    "patient_df = raw_df\n",
    "\n",
    "# Display the data\n",
    "patient_df.head()\n",
    "\n"
   ],
   "id": "e13a731379cb5b46",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   latitude  longitude\n",
       "0  -36.7875    174.610\n",
       "1  -36.8152    174.635\n",
       "2  -36.8385    174.627\n",
       "3  -36.8337    174.604\n",
       "4  -36.8430    174.612"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-36.7875</td>\n",
       "      <td>174.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-36.8152</td>\n",
       "      <td>174.635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-36.8385</td>\n",
       "      <td>174.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-36.8337</td>\n",
       "      <td>174.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-36.8430</td>\n",
       "      <td>174.612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T00:59:42.373620Z",
     "start_time": "2024-10-25T00:59:39.562942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle \n",
    "# Load the property coordinates from the Parquet file\n",
    "property_data = pd.read_parquet('data/nz_property_lat_lon.parquet')\n",
    "property_data = property_data.drop(columns=['WKT'])\n",
    "\n",
    "# Load the deduplicated dentists\n",
    "with open('data/deduplicated_dentists.pkl', 'rb') as f:\n",
    "    deduplicated_dentists = pickle.load(f)\n",
    "\n",
    "# Convert deduplicated_dentists to DataFrame for easier manipulation\n",
    "dentists_df = pd.DataFrame(deduplicated_dentists)\n",
    "dentists_df['size'] = dentists_df['reviews'].apply(ratings_to_size)\n",
    "\n",
    "# Display a few rows to verify\n",
    "display(property_data.head())\n",
    "display(dentists_df.head())\n"
   ],
   "id": "bd15b6eee77ec0cb",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Convert deduplicated_dentists to DataFrame for easier manipulation\u001B[39;00m\n\u001B[0;32m     11\u001B[0m dentists_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(deduplicated_dentists)\n\u001B[1;32m---> 12\u001B[0m dentists_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msize\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdentists_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mreviews\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mratings_to_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# Display a few rows to verify\u001B[39;00m\n\u001B[0;32m     15\u001B[0m display(property_data\u001B[38;5;241m.\u001B[39mhead())\n",
      "File \u001B[1;32m~\\PycharmProjects\\VENVs\\HuffModel2\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[0m\n\u001B[0;32m   4789\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4790\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4791\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4796\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4797\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4798\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4799\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4800\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4915\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4916\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   4917\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   4918\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4920\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4922\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m-> 4924\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\VENVs\\HuffModel2\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_compat()\n\u001B[0;32m   1426\u001B[0m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[1;32m-> 1427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\VENVs\\HuffModel2\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1501\u001B[0m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[0;32m   1504\u001B[0m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[0;32m   1505\u001B[0m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[0;32m   1506\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1507\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1508\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[0;32m   1509\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1512\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1513\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32m~\\PycharmProjects\\VENVs\\HuffModel2\\Lib\\site-packages\\pandas\\core\\base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[1;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[0;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[1;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\VENVs\\HuffModel2\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001B[0m, in \u001B[0;36mmap_array\u001B[1;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m   1741\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1743\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[0;32m   1746\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[0;32m   1747\u001B[0m     )\n",
      "File \u001B[1;32mlib.pyx:2972\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m, in \u001B[0;36mratings_to_size\u001B[1;34m(rating)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mratings_to_size\u001B[39m(rating):\n\u001B[1;32m----> 2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[43mmath\u001B[49m\u001B[38;5;241m.\u001B[39msqrt(rating) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m20\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m10\u001B[39m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'math' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T00:59:42.385626400Z",
     "start_time": "2024-10-25T00:50:20.950059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate distance between two points (Haversine formula)\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371  # Radius of Earth in kilometers\n",
    "    return c * r  # Distance in kilometers\n",
    "\n",
    "# Test the function\n",
    "print(haversine(-36.8485, 174.7633, -36.8484, 174.7634))  # Test distance in Auckland\n"
   ],
   "id": "18687aa4904b062",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014241458474257587\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T00:59:42.386626300Z",
     "start_time": "2024-10-25T00:50:22.118306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Locate the row corresponding to Massey Smiles in the dentists_df DataFrame\n",
    "massey_smiles_row = dentists_df[dentists_df['name'].str.contains('Massey Smiles', case=False)]\n",
    "\n",
    "# Extract the latitude and longitude for Massey Smiles\n",
    "massey_smiles_lat = massey_smiles_row['lat'].values[0]\n",
    "massey_smiles_lon = massey_smiles_row['lon'].values[0]\n",
    "massey_smiles_size = ratings_to_size(massey_smiles_row['reviews'].values[0])\n",
    "\n",
    "# Print the extracted location to verify\n",
    "print(f\"Massey Smiles Location: Latitude = {massey_smiles_lat}, Longitude = {massey_smiles_lon} Size = {massey_smiles_size}\")\n"
   ],
   "id": "9967bc303712d997",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Massey Smiles Location: Latitude = -36.82235440000001, Longitude = 174.6081585 Size = 2.8717797887081344\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-25T00:59:42.386626300Z",
     "start_time": "2024-10-25T00:50:23.725890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Massey Smiles' location (replace with actual latitude and longitude)\n",
    "\n",
    "# Calculate the distance of each patient to Massey Smiles using the Haversine formula\n",
    "patient_df['distance_to_massey_smiles'] = haversine(\n",
    "    patient_df['latitude'], patient_df['longitude'], massey_smiles_lat, massey_smiles_lon\n",
    ")\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(patient_df[['latitude', 'longitude', 'distance_to_massey_smiles']].head())\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   latitude  longitude  distance_to_massey_smiles\n",
      "0  -36.7875    174.610                   3.879099\n",
      "1  -36.8152    174.635                   2.518266\n",
      "2  -36.8385    174.627                   2.456669\n",
      "3  -36.8337    174.604                   1.314747\n",
      "4  -36.8430    174.612                   2.321005\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T00:59:42.387626500Z",
     "start_time": "2024-10-25T00:54:05.593242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define distance brackets (e.g., 0-1 km, 1-2 km, etc.)\n",
    "distance_brackets = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # You can adjust these as needed\n",
    "\n",
    "# Bin the patients based on their distance to Massey Smiles\n",
    "patient_df['distance_bracket'] = pd.cut(patient_df['distance_to_massey_smiles'], bins=distance_brackets)\n",
    "\n",
    "# Count the number of patients in each distance bracket\n",
    "actual_patient_distribution = patient_df['distance_bracket'].value_counts().sort_index()\n",
    "\n",
    "# Display the actual patient distribution by distance\n",
    "\n",
    "total_actual_patients = actual_patient_distribution.sum()\n",
    "actual_percentage_distribution = (actual_patient_distribution / total_actual_patients) * 100\n",
    "display(actual_percentage_distribution)"
   ],
   "id": "30dcb8a02381bb6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance_bracket\n",
       "(0, 1]      7.171686\n",
       "(1, 2]     20.987271\n",
       "(2, 3]     21.639242\n",
       "(3, 4]     15.212667\n",
       "(4, 5]      7.420056\n",
       "(5, 6]      8.351444\n",
       "(6, 7]      6.085067\n",
       "(7, 8]      5.650419\n",
       "(8, 9]      4.750078\n",
       "(9, 10]     2.732071\n",
       "Name: count, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T00:59:42.387626500Z",
     "start_time": "2024-10-25T00:54:34.670568Z"
    }
   },
   "cell_type": "code",
   "source": "display(actual_patient_distribution)",
   "id": "c4ecdfc6ffd0c44",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance_bracket\n",
       "(0, 1]     231\n",
       "(1, 2]     676\n",
       "(2, 3]     697\n",
       "(3, 4]     490\n",
       "(4, 5]     239\n",
       "(5, 6]     269\n",
       "(6, 7]     196\n",
       "(7, 8]     182\n",
       "(8, 9]     153\n",
       "(9, 10]     88\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T00:59:42.388626100Z",
     "start_time": "2024-10-25T00:50:42.747969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "property_lats = property_data['latitude'].values\n",
    "property_lons = property_data['longitude'].values\n",
    "dentist_sizes = dentists_df['size']"
   ],
   "id": "150d802d013f5da7",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T00:59:42.388626100Z",
     "start_time": "2024-10-25T00:52:51.744042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a function to predict the patient percentage distribution using the Huff model for Massey Smiles\n",
    "def predict_patient_percentage_distribution(beta):\n",
    "    # Calculate distances from all properties to Massey Smiles\n",
    "    distances = haversine(property_lats, property_lons, massey_smiles_lat, massey_smiles_lon)\n",
    "\n",
    "    # Calculate size-over-distance for each property\n",
    "    size_over_distance = massey_smiles_size / (distances ** beta)\n",
    "\n",
    "    # Normalize the size-over-distance values to get probabilities\n",
    "    total_size_over_distance = size_over_distance.sum()\n",
    "    if total_size_over_distance > 0:\n",
    "        normalized_probabilities = size_over_distance / total_size_over_distance\n",
    "    else:\n",
    "        normalized_probabilities = np.zeros_like(size_over_distance)\n",
    "\n",
    "    # Group properties into distance brackets and calculate the percentage of patients in each bracket\n",
    "    predicted_percentages = []\n",
    "    for bracket_start, bracket_end in zip(distance_brackets[:-1], distance_brackets[1:]):\n",
    "        # Mask distances within the current bracket\n",
    "        mask = (distances <= bracket_end) & (distances > bracket_start)\n",
    "        \n",
    "        # Sum the normalized probabilities for properties in the current bracket\n",
    "        bracket_probability_sum = normalized_probabilities[mask].sum()\n",
    "\n",
    "        # Append the percentage (between 0 and 1)\n",
    "        predicted_percentages.append(bracket_probability_sum)\n",
    "\n",
    "    # Convert to percentage (between 0 and 100)\n",
    "    predicted_percentages = np.array(predicted_percentages) * 100\n",
    "\n",
    "    return predicted_percentages\n",
    "\n",
    "# Example: Predict the distribution with a beta value of 2.0\n",
    "beta_test = 2.0\n",
    "predicted_percentage_distribution = predict_patient_percentage_distribution(beta_test)\n",
    "\n",
    "# Print the predicted percentage distribution\n",
    "print(\"Predicted patient percentage distribution:\", predicted_percentage_distribution)\n",
    "\n",
    "# Check the sum of the percentages to ensure it adds to 100\n",
    "print(\"Sum of predicted percentages:\", predicted_percentage_distribution.sum())\n"
   ],
   "id": "712d8688c420b119",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted patient percentage distribution: [9.80873626e+01 6.23736872e-01 2.39715604e-01 1.56317014e-01\n",
      " 1.33529296e-01 9.79799690e-02 5.40508246e-02 5.24418200e-02\n",
      " 4.24474589e-02 4.20120449e-02]\n",
      "Sum of predicted percentages: 99.52959348915832\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T00:59:42.389626100Z",
     "start_time": "2024-10-25T00:57:07.424222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to calculate error between actual and predicted distribution\n",
    "def calculate_error(actual, predicted):\n",
    "    return np.sum((actual - predicted) ** 2)\n"
   ],
   "id": "4023f116ed9f7117",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T00:59:42.389626100Z",
     "start_time": "2024-10-25T00:59:20.515512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Tune beta between a lower range to minimize the error\n",
    "best_beta = None\n",
    "best_error = float('inf')\n",
    "\n",
    "# Iterate over a lower range of beta values\n",
    "for beta in tqdm(np.arange(0.1, 2.0, 0.1), desc=\"Tuning Beta\"):\n",
    "    predicted_percentage_distribution = predict_patient_percentage_distribution(beta)\n",
    "    error = calculate_error(actual_percentage_distribution.values, predicted_percentage_distribution)\n",
    "\n",
    "    if error < best_error:\n",
    "        best_beta = beta\n",
    "        best_error = error\n",
    "\n",
    "# Output the best beta and minimum error\n",
    "print(f\"Best Beta (Lowered Range): {best_beta}\")\n",
    "print(f\"Minimum Error (Lowered Range): {best_error}\")\n",
    "\n",
    "# Print actual vs predicted for visual comparison\n",
    "print(\"\\nActual Patient Percentage Distribution:\", actual_percentage_distribution.values)\n",
    "print(\"Predicted Patient Percentage Distribution (Best Beta):\", predict_patient_percentage_distribution(best_beta))\n"
   ],
   "id": "27f6f423d4ee7f2d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning Beta: 100%|██████████| 19/19 [00:06<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Beta (Lowered Range): 1.1\n",
      "Minimum Error (Lowered Range): 689.4772602224191\n",
      "\n",
      "Actual Patient Percentage Distribution: [ 7.17168581 20.98727103 21.63924247 15.21266687  7.42005588  8.35144365\n",
      "  6.08506675  5.65041912  4.75007762  2.73207079]\n",
      "Predicted Patient Percentage Distribution (Best Beta): [11.86062873  7.28166417  4.44569158  4.00902829  4.29957567  3.77457872\n",
      "  2.4050313   2.6780448   2.41804964  2.65088208]\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "156425f199bc8c22"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
